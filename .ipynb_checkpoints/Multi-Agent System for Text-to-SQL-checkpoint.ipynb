{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378c7f11-8a03-43e1-b273-fff88238b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ollama\n",
    "from ollama import Client\n",
    "import subprocess\n",
    "from autogen import AssistantAgent, UserProxyAgent, GroupChat, GroupChatManager\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "from typing import Dict, Any\n",
    "import torch\n",
    "import pymysql\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "import psutil\n",
    "from GPUtil import getGPUs\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fbe42c-9789-4543-8194-e8f9b8b733d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory/1e9:.2f} GB\")\n",
    "print(f\"Compute Capability: {torch.cuda.get_device_capability()}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "gpu = getGPUs()[0]\n",
    "print(f\"GPU Memory: {gpu.memoryUsed}\")\n",
    "print(f\"Virtual Memory: {psutil.virtual_memory().percent}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea5f89-3e1d-404f-b0e5-3288d08c5eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    subprocess.run([\"ollama\", \"serve\"], check=True, shell=True, timeout=5)\n",
    "except:\n",
    "    pass  # Already running in another terminal\n",
    "\n",
    "# llama3.3:70b-instruct-q4_K_S\n",
    "# sqlcoder:70b-alpha-q3_K_L\n",
    "\n",
    "def verify_models():\n",
    "    available_models = [m['name'] for m in ollama.list()['models']]\n",
    "    required_models = [\n",
    "        \"sqlcoder:15b-q3_K_L\",\n",
    "        \"phi4-reasoning:14b-plus-q4_K_M\"\n",
    "    ]\n",
    "    \n",
    "    for model in required_models:\n",
    "        if model not in available_models:\n",
    "            print(f\"Model {model} not found! Pulling...\")\n",
    "            ollama.pull(model)\n",
    "\n",
    "verify_models()\n",
    "    \n",
    "def list_ollama_models():\n",
    "    try:\n",
    "        # Explicitly configure client for Windows\n",
    "        client = Client(host='http://localhost:11434')\n",
    "        \n",
    "        # Verify connection\n",
    "        # client.heartbeat()\n",
    "        \n",
    "        # Get models with error handling\n",
    "        response = client.list()\n",
    "        models = response.get('models', [])\n",
    "        \n",
    "        if not models:\n",
    "            print(\"No models found. Install models using 'ollama pull <model_name>'\")\n",
    "            return\n",
    "            \n",
    "        print(\"\\nAvailable Ollama Models:\")\n",
    "        print(f\"{'Model Name':<40} {'Size':<15} {'Modified'}\")\n",
    "        print(\"-\" * 70)\n",
    "        for model in models:\n",
    "            print(f\"{model.get('model', 'N/A'):<40} \"\n",
    "                  f\"{model.get('size', 0)/1e9:.2f} GB  \"\n",
    "                  f\"{model.get('modified_at', 'N/A')}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        print(\"1. Ensure 'ollama serve' is running in a separate terminal\")\n",
    "        print(\"2. Check firewall settings allowing port 11434\")\n",
    "        print(\"3. Verify Ollama version with 'ollama --version'\")\n",
    "\n",
    "# Execute the function\n",
    "list_ollama_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23e09c6-e9e8-4a30-ace0-fdcddbf6f7b8",
   "metadata": {},
   "source": [
    "# Setup MySQL functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54212bc-0b99-44be-99d7-29c78f9de343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_mysql():\n",
    "    # Open database connection\n",
    "    # Connect to the database\"\n",
    "    db = pymysql.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"1234\",\n",
    "        database=\"BIRD\",\n",
    "        #unix_socket=\"/tmp/mysql.sock\",\n",
    "        port=3306,\n",
    "    )\n",
    "    return db\n",
    "\n",
    "def execute_mysql_query(cursor, query):\n",
    "    \"\"\"Execute a MySQL query with error handling.\"\"\"\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        # Only fetch results if it's a SELECT-like query\n",
    "        if cursor.description:  # Checks if there are results to fetch\n",
    "            return cursor.fetchall()\n",
    "        return None  # For non-result queries like INSERT/UPDATE\n",
    "    except pymysql.Error as e:\n",
    "        print(f\"[QUERY ERROR] {e.args[1]}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"[UNEXPECTED ERROR] During query execution: {e}\")\n",
    "        return None\n",
    "\n",
    "def perform_query(query):\n",
    "    \"\"\"Execute query with connection safety and error handling.\"\"\"\n",
    "    db = None\n",
    "    try:\n",
    "        db = connect_mysql()\n",
    "        cursor = db.cursor()\n",
    "        result = execute_mysql_query(cursor, query)\n",
    "        \n",
    "        # Commit if needed (for write operations)\n",
    "        if query.strip().lower().startswith((\"insert\", \"update\", \"delete\")):\n",
    "            db.commit()\n",
    "            \n",
    "        return result\n",
    "    except pymysql.Error as e:\n",
    "        print(f\"[DATABASE ERROR] Connection/execution failed: {e}\")\n",
    "        if db:  # Rollback if transaction exists\n",
    "            db.rollback()\n",
    "        return None\n",
    "    finally:\n",
    "        if db:\n",
    "            db.close()\n",
    "\n",
    "def get_bird_schema():\n",
    "    \"\"\"\n",
    "    Retrieves the schema of the BIRD database, including tables, columns, and related tables.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary where each key is a table name, and the value is another dictionary\n",
    "        containing 'columns' (list of column names and types) and 'related_tables' (list of related tables).\n",
    "    \"\"\"\n",
    "    # Query to get all tables in the BIRD database\n",
    "    table_query = \"\"\"\n",
    "        SELECT TABLE_NAME \n",
    "        FROM INFORMATION_SCHEMA.TABLES \n",
    "        WHERE TABLE_SCHEMA = 'BIRD';\n",
    "    \"\"\"\n",
    "    tables_result = perform_query(table_query)\n",
    "    tables = [row[0] for row in tables_result]\n",
    "\n",
    "    schema = {}\n",
    "\n",
    "    # Retrieve columns for each table\n",
    "    for table in tables:\n",
    "        column_query = f\"\"\"\n",
    "            SELECT COLUMN_NAME, DATA_TYPE \n",
    "            FROM INFORMATION_SCHEMA.COLUMNS \n",
    "            WHERE TABLE_SCHEMA = 'BIRD' AND TABLE_NAME = '{table}';\n",
    "        \"\"\"\n",
    "        columns_result = perform_query(column_query)\n",
    "        columns = [{'name': col[0], 'type': col[1]} for col in columns_result]\n",
    "        schema[table] = {\n",
    "            'columns': columns,\n",
    "            'related_tables': []\n",
    "        }\n",
    "\n",
    "    # Retrieve foreign key relationships within the BIRD database\n",
    "    fk_query = \"\"\"\n",
    "        SELECT DISTINCT TABLE_NAME, REFERENCED_TABLE_NAME \n",
    "        FROM INFORMATION_SCHEMA.KEY_COLUMN_USAGE \n",
    "        WHERE TABLE_SCHEMA = 'BIRD' \n",
    "            AND REFERENCED_TABLE_SCHEMA = 'BIRD' \n",
    "            AND REFERENCED_TABLE_NAME IS NOT NULL;\n",
    "    \"\"\"\n",
    "    fk_result = perform_query(fk_query)\n",
    "\n",
    "    # Populate related_tables (both directions)\n",
    "    for source_table, related_table in fk_result:\n",
    "        # Add related table to the source table's list\n",
    "        if source_table in schema and related_table not in schema[source_table]['related_tables']:\n",
    "            schema[source_table]['related_tables'].append(related_table)\n",
    "        # Add source table to the related table's list\n",
    "        if related_table in schema and source_table not in schema[related_table]['related_tables']:\n",
    "            schema[related_table]['related_tables'].append(source_table)\n",
    "\n",
    "    return schema\n",
    "    \n",
    "def perform_query_on_mysql_databases(query: str) -> str:\n",
    "    \"\"\"User-facing query executor with string conversion\"\"\"\n",
    "    result = perform_query(query)\n",
    "    return str(result) if result else \"ERROR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf384d05-118e-46d6-9c85-951f3710eb48",
   "metadata": {},
   "source": [
    "# Test MySQL Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6fade9-f3fe-437a-a5de-48b9e7dcb6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test connection\n",
    "try:\n",
    "    conn = connect_mysql()\n",
    "    print(\"Successfully connected to MySQL!\")\n",
    "    conn.close()\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")\n",
    "    \n",
    "schema = get_bird_schema()\n",
    "# for table, details in schema.items():\n",
    "#     print(f\"Table: {table}\")\n",
    "#     print(f\"Columns: {[col['name'] for col in details['columns']]}\")\n",
    "#     print(f\"Related Tables: {details['related_tables']}\\n\")\n",
    "\n",
    "### Syntax to execute the query ###\n",
    "# query = \"\"\" \"\"\"\n",
    "# result = perform_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f52df-d331-4f83-adf6-08763b186861",
   "metadata": {},
   "source": [
    "# LLM Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6568f-f1ec-41ee-9f93-0b1d9b50a50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Hardware Optimization Setup\n",
    "# --------------------------\n",
    "# def optimize_ollama_models():\n",
    "#     # Configure Ollama to use GPU layers efficiently\n",
    "#     ollama_model_config = {\n",
    "#         \"sqlcoder:15b-q3_K_L\": {\n",
    "#             \"num_gpu\": 18,  # Layers on GPU (fits 6GB VRAM)\n",
    "#             \"num_ctx\": 768,  # Reduced context window\n",
    "#             \"num_threads\": 4,  # CPU threads\n",
    "#         },\n",
    "#         \"phi4-reasoning:14b-plus-q4_K_M\": {\n",
    "#             \"num_gpu\": 16,\n",
    "#             \"num_ctx\": 768,\n",
    "#             \"num_threads\": 4,\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "#     client = Client()\n",
    "    \n",
    "#     # Apply configurations\n",
    "#     for model, config in ollama_model_config.items():\n",
    "#         modelfile = f\"\"\"\n",
    "#             FROM {model}\n",
    "#             PARAMETER num_gpu {config['num_gpu']}\n",
    "#             PARAMETER num_ctx {config['num_ctx']}\n",
    "#             PARAMETER num_threads {config['num_threads']}\n",
    "#             PARAMETER numa true\n",
    "#         \"\"\"\n",
    "        \n",
    "#         # Write Modelfile to disk\n",
    "#         modelfile_path = f\"{model.replace(':', '_')}.Modelfile\"\n",
    "#         with open(modelfile_path, \"w\") as f:\n",
    "#             f.write(modelfile.strip())\n",
    "            \n",
    "#         client.create(\n",
    "#             model=model,\n",
    "#             from_=model\n",
    "#         )\n",
    "\n",
    "#         # Optionally, remove the Modelfile after creation\n",
    "#         os.remove(modelfile_path)\n",
    "\n",
    "# optimize_ollama_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790c89ad-1912-4fe9-a9b9-c5b3b5ddbd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MemoryAwareManager(CustomGroupChatManager):\n",
    "#     def __init__(self, *args, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         self.active_model = None\n",
    "        \n",
    "#     def switch_model(self, model_name):\n",
    "#         \"\"\"Unload current model and load new one\"\"\"\n",
    "#         if self.active_model:\n",
    "#             ollama.delete(self.active_model)\n",
    "#         ollama.create(model_name)\n",
    "#         self.active_model = model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe6a79-b43a-4d92-82f9-6ffb643dc6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Modified Agent Workflow\n",
    "# --------------------------\n",
    "def sequential_workflow(question_data):\n",
    "    \"\"\"Process one question at a time with memory cleanup\"\"\"\n",
    "    manager = MemoryAwareManager(...)  # Initialize with previous config\n",
    "    \n",
    "    # Phase 1: Schema Mapping\n",
    "    manager.switch_model(\"phi4-reasoning:14b-plus-q4_K_M\")\n",
    "    schema_result = agent1.generate_reply(\n",
    "        f\"Question: {question_data['question']}\\nSchema: {SCHEMA}\"\n",
    "    )\n",
    "    \n",
    "    # Phase 2: SQL Generation\n",
    "    manager.switch_model(\"sqlcoder:15b-q3_K_L\")\n",
    "    sql_query = agent2.generate_reply(schema_result)\n",
    "    \n",
    "    # Phase 3: Validation\n",
    "    manager.switch_model(\"phi4-reasoning:14b-plus-q4_K_M\")\n",
    "    validation_result = agent3.validate_query(sql_query)\n",
    "    \n",
    "    return validation_result\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Resource Monitoring\n",
    "# --------------------------\n",
    "def resource_monitor():\n",
    "    \"\"\"Check available resources before each operation\"\"\"\n",
    "    if gpu.memoryUsed > 5500:  # 6GB VRAM\n",
    "        raise MemoryError(\"GPU memory exhausted\")\n",
    "    \n",
    "    if psutil.virtual_memory().percent > 90:\n",
    "        raise MemoryError(\"System memory exhausted\")\n",
    "\n",
    "# --------------------------\n",
    "# Modified Agent Classes\n",
    "# --------------------------\n",
    "# class SafeAssistantAgent(AssistantAgent):\n",
    "#     def generate_reply(self, *args, **kwargs):\n",
    "#         resource_monitor()\n",
    "#         return super().generate_reply(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d523f2c0-8b16-4b90-af3a-66fb13a2b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for Ollama models\n",
    "LLM_CONFIG = [\n",
    "    {  # First model config\n",
    "        \"model\": \"sqlcoder:15b-q3_K_L\",\n",
    "        \"base_url\": \"http://localhost:11434/v1\",\n",
    "        \"api_key\": \"ollama\",\n",
    "    },\n",
    "    {  # Second model config\n",
    "        \"model\": \"phi4-reasoning:14b-plus-q4_K_M\", \n",
    "        \"base_url\": \"http://localhost:11434/v1\",\n",
    "        \"api_key\": \"ollama\",\n",
    "    }\n",
    "]\n",
    "# Define LLM clients for each model\n",
    "# llama3_client = OllamaChatCompletionClient(model=\"phi4-reasoning:14b-plus-q4_K_M\")\n",
    "# sqlcoder_client = OllamaChatCompletionClient(model=\"sqlcoder:15b-q3_K_L\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404f46d2-d49b-4696-a996-1182cdc1f093",
   "metadata": {},
   "source": [
    "# Define Multi-Agent architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b0e35-106d-4342-9304-9ff23f35d888",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGroupChatManager(GroupChatManager):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.accuracy_data = {\"total\": 0, \"success\": 0}\n",
    "    \n",
    "    def track_success(self, success: bool):\n",
    "        self.accuracy_data[\"total\"] += 1\n",
    "        if success:\n",
    "            self.accuracy_data[\"success\"] += 1\n",
    "    \n",
    "    def get_accuracy(self):\n",
    "        if self.accuracy_data[\"total\"] == 0:\n",
    "            return 0.0\n",
    "        return (self.accuracy_data[\"success\"] / self.accuracy_data[\"total\"]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c227c7e3-fff6-4b7d-9724-8d28cf6921c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1: Schema Mapping Agent\n",
    "agent1 = AssistantAgent(\n",
    "    name=\"Schema_Mapper\",\n",
    "    system_message=\"\"\"You are a database schema expert. Analyze the input question and map it to the database schema.\n",
    "    Available schema format for the current database:\n",
    "    {schema}\n",
    "    \n",
    "    Output format must be JSON with tables as keys and values containing:\n",
    "    - columns: list of relevant columns for the input\n",
    "    - related_tables: list of tables needing joins\n",
    "    \"\"\".format(\n",
    "        schema_example=json.dumps({\n",
    "            \"account\": {\n",
    "                \"columns\": [\"account_id\", \"district_id\", \"frequency\", \"date\"],\n",
    "                \"related_tables\": [\"district\", \"disp\", \"loan\", \"order\", \"trans\"]\n",
    "            },\n",
    "            \"alignment\": {\n",
    "                \"columns\": [\"id\", \"alignment\"],\n",
    "                \"related_tables\": [\"superhero\"]\n",
    "            }\n",
    "        }, indent=2),\n",
    "        schema=json.dumps(schema, indent=2)\n",
    "    ),\n",
    "    llm_config={\n",
    "        \"config_list\": [{\n",
    "            \"model\": LLM_CONFIG[1][\"model\"],\n",
    "            \"base_url\": LLM_CONFIG[1][\"base_url\"],\n",
    "            \"api_key\": LLM_CONFIG[1][\"api_key\"]\n",
    "        }]\n",
    "    },\n",
    "    max_consecutive_auto_reply=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f46318-42b1-41b3-88a3-085f89499da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 2: SQL Generation Agent\n",
    "agent2 = AssistantAgent(\n",
    "    name=\"SQL_Generator\",\n",
    "    system_message=\"\"\"You are an expert SQL writer. Using the schema analysis from Schema_Mapper:\n",
    "    1. Break down complex questions into subqueries\n",
    "    2. Handle joins, nested queries, and aggregation\n",
    "    3. Ensure MySQL syntax compliance\n",
    "    4. Consider performance optimization\n",
    "    5. Execute the sql query using the below function map and record the status of SQL query execution along with the  SQL query\n",
    "    Return ONLY the SQL query without any explanation.\"\"\",\n",
    "    llm_config={\n",
    "        \"config_list\": [{\n",
    "            \"model\": LLM_CONFIG[0][\"model\"],\n",
    "            \"base_url\": LLM_CONFIG[0][\"base_url\"],\n",
    "            \"api_key\": LLM_CONFIG[0][\"api_key\"]\n",
    "        }]\n",
    "    },\n",
    "    max_consecutive_auto_reply=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793820c5-f8c0-4e53-8351-2505dddb0045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 3: Validation & Feedback Agent\n",
    "agent3 = UserProxyAgent(\n",
    "    name=\"SQL_Validator\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    system_message=\"\"\"Validate the output of SQL queries by comparing it with the input text and check if all the criteria has been satisfied along with successful execution for output SQL query. Provide RLAIF feedback:\n",
    "    - If successful: \"SUCCESS: [execution result]\"\n",
    "    - If failed: \"ERROR: [error details]. Needed corrections: [specific fixes]\"\n",
    "    Maintain conversation history for iterative improvements.\"\"\",\n",
    "    code_execution_config={\"work_dir\": \"coding\", \"use_docker\": False},\n",
    "    llm_config={\n",
    "        \"config_list\": [{\n",
    "            \"model\": LLM_CONFIG[1][\"model\"],\n",
    "            \"base_url\": LLM_CONFIG[1][\"base_url\"],\n",
    "            \"api_key\": LLM_CONFIG[1][\"api_key\"]\n",
    "        }]\n",
    "    },\n",
    "    function_map={\"perform_query_on_mysql_databases\": perform_query_on_mysql_databases},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba203945-5c6f-417f-8915-7e25950eedfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 4: Group Manager\n",
    "agent4 = CustomGroupChatManager(\n",
    "    groupchat=GroupChat(\n",
    "        agents=[agent1, agent2, agent3],\n",
    "        messages=[],\n",
    "        max_round=10,\n",
    "        speaker_selection_method=\"round_robin\",\n",
    "    ),\n",
    "    name=\"Group_Manager\",\n",
    "    system_message=\"Monitor SQL generation process. Ensure query execution accuracy >70%. Current execution accuracy: {accuracy}%\",\n",
    "    llm_config={\n",
    "        \"config_list\": [{\n",
    "            \"model\": LLM_CONFIG[1][\"model\"],\n",
    "            \"base_url\": LLM_CONFIG[1][\"base_url\"],\n",
    "            \"api_key\": LLM_CONFIG[1][\"api_key\"]\n",
    "        }]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a9e5e-72d5-4b80-810c-fa84bd7f9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register functions for execution\n",
    "@agent3.register_for_execution()\n",
    "@agent2.register_for_llm(description=\"Execute SQL query and return results\")\n",
    "def perform_query_on_mysql(query: str) -> str:\n",
    "    \"\"\"Execute SQL query and return results as string\"\"\"\n",
    "    result = perform_query(query)\n",
    "    return str(result) if result else \"ERROR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97302d2-5c57-43d3-baf5-ed72ee3bd2bf",
   "metadata": {},
   "source": [
    "# Test the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c21136-97c0-4a3a-9d74-b1c082abb7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Windows path handling for data files\n",
    "def get_windows_path(relative_path):\n",
    "    return str(Path(os.getcwd()) / relative_path)\n",
    "# Test pipeline\n",
    "def test_sql_generation(input_file: str, gold_file: str):\n",
    "    with open(input_file) as f:\n",
    "        test_cases = json.load(f)\n",
    "    \n",
    "    with open(gold_file) as f:\n",
    "        gold_queries = f.read().split(';')\n",
    "    \n",
    "    for case in test_cases:\n",
    "        print(f\"\\nProcessing case: {case['question']}\")\n",
    "        agent4.reset()\n",
    "        agent1.reset()\n",
    "        agent2.reset()\n",
    "        agent3.reset()\n",
    "        \n",
    "        # Initiate conversation\n",
    "        # Database: {case['db_id']}\n",
    "        agent4.initiate_chat(\n",
    "            agent1,\n",
    "            message=f\"\"\"\n",
    "            Question: {case['question']}\n",
    "            Evidence: {case['evidence']}\n",
    "            Goal: Generate executable SQL query for the given question\n",
    "            \"\"\",\n",
    "        )\n",
    "        \n",
    "        # Validate against gold standard\n",
    "        generated_query = extract_last_query(agent4.chat_messages[agent3])\n",
    "        gold_query = next(q for q in gold_queries if case['question'] in q)\n",
    "        success = compare_queries(generated_query, gold_query)\n",
    "        agent4.track_success(success)\n",
    "\n",
    "        print(f\"Accuracy: {agent4.get_accuracy():.2f}%\")\n",
    "\n",
    "def extract_last_query(messages: list) -> str:\n",
    "    for msg in reversed(messages):\n",
    "        if 'content' in msg and 'SELECT' in msg['content']:\n",
    "            return msg['content'].split('```sql')[-1].split('```')[0].strip()\n",
    "    return \"\"\n",
    "\n",
    "def compare_queries(generated: str, gold: str) -> bool:\n",
    "    def normalize_query(query):\n",
    "        return \" \".join(query.lower().split()).replace(\";\", \"\").strip()\n",
    "    \n",
    "    return normalize_query(generated) == normalize_query(gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013cb073-e68d-4540-bba5-a33bac357066",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Verify MySQL connection\n",
    "    conn = connect_mysql()\n",
    "    conn.close()\n",
    "    resource_monitor()\n",
    "    \n",
    "    # Run test pipeline\n",
    "    test_sql_generation(\n",
    "        \"./mini_dev/data_minidev/data_minidev/MINIDEV/mini_dev_mysql.json\",\n",
    "        \"./mini_dev/data_minidev/data_minidev/MINIDEV/mini_dev_mysql_gold.sql\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Initialization failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
